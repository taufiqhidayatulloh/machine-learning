{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taufiqhidayatulloh/machine-learning/blob/main/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementasi normalisasi"
      ],
      "metadata": {
        "id": "Tj-6-b25i1e2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tun2ZekxfdDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c79e40-3ed4-42b6-b00d-1bd89fa30215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
          ]
        }
      ],
      "source": [
        "def norm_data(data):\n",
        "  '''\n",
        "  Melakukan normalisasi data.\n",
        "\n",
        "  Parameters:\n",
        "    data (list) : Data yang akan dinormalisasi\n",
        "\n",
        "  Returns:\n",
        "    data (list) : Data hasil normalisasi\n",
        "  '''\n",
        "\n",
        "  data_max = max(data)\n",
        "  data_min = min(data)\n",
        "  data_len = len(data)\n",
        "\n",
        "  for i in range(0, data_len):\n",
        "    data[i] = (data[i] - data_min) / (data_max-data_min)\n",
        "\n",
        "  return data\n",
        "\n",
        "# Contoh\n",
        "data = [10, 11, 12, 14, 16]\n",
        "n_data = norm_data(data)\n",
        "print(n_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementasi normalisasi dengan\n",
        "menggunakan library Scikit-learn untuk kasus data fitur dalam bentuk 2 dimensi"
      ],
      "metadata": {
        "id": "3SsxfMtTi3ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "np.set_printoptions(precision=6) #pembulatan 4 angka koma\n",
        "np.set_printoptions(suppress=True) #hilangkan nilai e\n",
        "\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003]\n",
        "]\n",
        "\n",
        "data = np.asarray(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled = scaler.fit_transform(data)\n",
        "print('Data Ternormalisasi')\n",
        "print(scaled)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU8iZfONi7N6",
        "outputId": "2e9d2109-5e03-4aa6-93fa-c216914209ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Ternormalisasi\n",
            "[[1.       0.      ]\n",
            " [0.285714 1.      ]\n",
            " [0.       0.058116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementasi Ordinal Encoding"
      ],
      "metadata": {
        "id": "tWDa8bynn_9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "oe = OrdinalEncoder()\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "transform_oe = oe.fit_transform(data)\n",
        "\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "print('Data Transformasi Ordinal Encoder')\n",
        "print(transform_oe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabrZfSPoBDQ",
        "outputId": "4e6efa69-dfff-4185-afa2-5d481e81ec84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi Ordinal Encoder\n",
            "[[2.]\n",
            " [0.]\n",
            " [1.]\n",
            " [3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementasi One-Hot Encoding"
      ],
      "metadata": {
        "id": "ewebJBqmpKTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "transform_ohe = ohe.fit_transform(data)\n",
        "\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "print('Data Transformasi One Hot Encoding')\n",
        "print(transform_ohe.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTPYmTi4pMEc",
        "outputId": "cdd22bc9-e0d4-40e8-bb95-142d7b71a2f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One Hot Encoding\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementasi Dummy Variable Encoding"
      ],
      "metadata": {
        "id": "AtvduXnwp_f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "de = OneHotEncoder(drop='first')\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "transform_de = de.fit_transform(data)\n",
        "\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "print('Data Transformasi One Hot Encoding')\n",
        "print(transform_de.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XVaHqObqAb7",
        "outputId": "a2cfc08c-ffa8-4e96-beb1-e67d7e62fc10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One Hot Encoding\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Studi Kasus Ekstrasi Fitur dari Data Teks"
      ],
      "metadata": {
        "id": "ogBF7HKdqvHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['the house had a tiny little mouse',\n",
        "          'the cat saw the mouse',\n",
        "          'the mouse ran away from the house',\n",
        "          'the cat finally ate the house',\n",
        "          'the end of the mouse story']\n",
        "\n"
      ],
      "metadata": {
        "id": "ssWEMl_XqvtK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y-68mB5rJf9",
        "outputId": "8f089bf6-8739-4a14-ebd8-4c899ebcce1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 7)\t0.33875373403393194\n",
            "  (0, 6)\t0.6012854497921586\n",
            "  (0, 11)\t0.6012854497921586\n",
            "  (0, 5)\t0.4026878734386609\n",
            "  (1, 9)\t0.7127752157729959\n",
            "  (1, 2)\t0.5750625560879445\n",
            "  (1, 7)\t0.4015651234424611\n",
            "  (2, 1)\t0.6012854497921586\n",
            "  (2, 8)\t0.6012854497921586\n",
            "  (2, 7)\t0.338753734033932\n",
            "  (2, 5)\t0.40268787343866097\n",
            "  (3, 0)\t0.5680140774328015\n",
            "  (3, 4)\t0.5680140774328015\n",
            "  (3, 2)\t0.45827018116532225\n",
            "  (3, 5)\t0.38040564760664297\n",
            "  (4, 10)\t0.6569003716341058\n",
            "  (4, 3)\t0.6569003716341058\n",
            "  (4, 7)\t0.3700862108940939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro4VWk4psVki",
        "outputId": "7f9b768e-3cbc-49f4-e88d-63562abd2751"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ate', 'away', 'cat', 'end', 'finally', 'house', 'little', 'mouse',\n",
              "       'ran', 'saw', 'story', 'tiny'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['the house had a tiny little mouse',\n",
        "          'the cat saw the mouse',\n",
        "          'the mouse ran away from the house',\n",
        "          'the cat finally ate the house',\n",
        "          'the end of the mouse story']\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "print('Hasil TF-IDF')\n",
        "print(resp)\n",
        "\n",
        "print('Hasil Token')\n",
        "print(vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf3D3-HVsb7L",
        "outputId": "789bb44c-c177-4141-f460-c195344cfb23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil TF-IDF\n",
            "  (0, 7)\t0.33875373403393194\n",
            "  (0, 6)\t0.6012854497921586\n",
            "  (0, 11)\t0.6012854497921586\n",
            "  (0, 5)\t0.4026878734386609\n",
            "  (1, 9)\t0.7127752157729959\n",
            "  (1, 2)\t0.5750625560879445\n",
            "  (1, 7)\t0.4015651234424611\n",
            "  (2, 1)\t0.6012854497921586\n",
            "  (2, 8)\t0.6012854497921586\n",
            "  (2, 7)\t0.338753734033932\n",
            "  (2, 5)\t0.40268787343866097\n",
            "  (3, 0)\t0.5680140774328015\n",
            "  (3, 4)\t0.5680140774328015\n",
            "  (3, 2)\t0.45827018116532225\n",
            "  (3, 5)\t0.38040564760664297\n",
            "  (4, 10)\t0.6569003716341058\n",
            "  (4, 3)\t0.6569003716341058\n",
            "  (4, 7)\t0.3700862108940939\n",
            "Hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BDEWpnIrrJIp"
      }
    }
  ]
}